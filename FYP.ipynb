{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4680cce-00d0-43f8-a0e9-6b261abe4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\aksha\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (0.3.52)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (0.3.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\aksha\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.52 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain_openai) (0.3.52)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain_openai) (1.74.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (0.3.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_openai) (2.11.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.52->langchain_openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.52->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.52->langchain_openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.52->langchain_openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966f7465-bbad-4946-8534-701e995f17f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price            Close        High         Low        Open     Volume\n",
      "Ticker            AAPL        AAPL        AAPL        AAPL       AAPL\n",
      "Date                                                                 \n",
      "2010-01-04    6.440331    6.455077    6.391279    6.422877  493729600\n",
      "2010-01-05    6.451464    6.487877    6.417458    6.458085  601904800\n",
      "2010-01-06    6.348846    6.477045    6.342226    6.451466  552160000\n",
      "2010-01-07    6.337110    6.379844    6.291067    6.372320  477131200\n",
      "2010-01-08    6.379240    6.379842    6.291368    6.328683  447610800\n",
      "...                ...         ...         ...         ...        ...\n",
      "2022-12-23  130.344513  130.898074  128.150027  129.415314   63814900\n",
      "2022-12-27  128.535492  129.899636  127.240551  129.869982   69007800\n",
      "2022-12-28  124.591385  129.524031  124.423341  128.179661   85438400\n",
      "2022-12-29  128.120346  128.980342  126.261956  126.518963   75703700\n",
      "2022-12-30  128.436661  128.456435  125.965402  126.934142   77034200\n",
      "\n",
      "[3272 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "data = yf.download(\"AAPL\", start=\"2010-01-01\", end=\"2023-01-01\")\n",
    "#returns = data.pct_change().dropna()\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec27d69-c832-43a0-8f72-e164c29e451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting black_litterman.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile black_litterman.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    num_assets = 2 #int(input(\"Enter the number of stocks: \"))\n",
    "    stock_symbols = []\n",
    "\n",
    "    stock_symbols.append(\"AAPL\")\n",
    "    stock_symbols.append(\"MSFT\")\n",
    "\n",
    "    time_horizon = 0.019*2\n",
    "    return stock_symbols, time_horizon\n",
    "\n",
    "def fetch_historical_data(stock_symbols, start_date=\"2010-01-01\", end_date=\"2023-01-01\"):\n",
    "    data = yf.download(stock_symbols, start=start_date, end=end_date)['Close']\n",
    "    returns = data.pct_change().dropna()\n",
    "    return returns\n",
    "\n",
    "def calculate_expected_returns_and_cov_matrix(returns, time_horizon):\n",
    "    expected_returns = returns.mean() * time_horizon\n",
    "    cov_matrix = returns.cov() * time_horizon\n",
    "    return expected_returns, cov_matrix\n",
    "\n",
    "def calculate_market_equilibrium_returns(cov_matrix, market_caps):\n",
    "    market_weights = market_caps / np.sum(market_caps)\n",
    "    equilibrium_returns = np.dot(cov_matrix, market_weights)\n",
    "    return equilibrium_returns\n",
    "\n",
    "def adjust_returns_with_views(equilibrium_returns, cov_matrix, P, Q, omega):\n",
    "    tau = 0.025\n",
    "    M_inverse = np.linalg.inv(np.dot(np.dot(tau, P), np.dot(cov_matrix, P.T)) + omega)\n",
    "    adjusted_returns = equilibrium_returns + np.dot(np.dot(np.dot(cov_matrix, P.T), M_inverse), (Q - np.dot(P, equilibrium_returns)))\n",
    "    return adjusted_returns\n",
    "\n",
    "def portfolio_variance(weights, cov_matrix):\n",
    "    return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "\n",
    "def portfolio_return(weights, expected_returns):\n",
    "    return np.dot(weights, expected_returns)\n",
    "\n",
    "def optimize_portfolio(expected_returns, cov_matrix, target_return):\n",
    "    num_assets = len(expected_returns)\n",
    "\n",
    "    def constraint(weights):\n",
    "        return np.sum(weights) - 1\n",
    "\n",
    "    def return_constraint(weights):\n",
    "        return portfolio_return(weights, expected_returns) - target_return\n",
    "\n",
    "    bounds = [(0, 1) for _ in range(num_assets)]\n",
    "    initial_weights = [1. / num_assets] * num_assets\n",
    "\n",
    "    result = minimize(portfolio_variance, initial_weights, args=(cov_matrix,), method='SLSQP', bounds=bounds, constraints=[{'type': 'eq', 'fun': constraint}, {'type': 'eq', 'fun': return_constraint}])\n",
    "\n",
    "    return result.x\n",
    "\n",
    "def calculate_efficient_frontier(expected_returns, cov_matrix, num_portfolios=100):\n",
    "    target_returns = np.linspace(min(expected_returns), max(expected_returns), num_portfolios)\n",
    "    frontier_returns = []\n",
    "    frontier_risks = []\n",
    "    frontier_weights = []\n",
    "\n",
    "    for target_return in target_returns:\n",
    "        weights = optimize_portfolio(expected_returns, cov_matrix, target_return)\n",
    "        frontier_returns.append(portfolio_return(weights, expected_returns))\n",
    "        frontier_risks.append(np.sqrt(portfolio_variance(weights, cov_matrix)))\n",
    "        frontier_weights.append(weights)\n",
    "\n",
    "    return frontier_returns, frontier_risks, frontier_weights\n",
    "\n",
    "def plot_efficient_frontier(frontier_returns, frontier_risks, frontier_weights, risk_free_rate=0.0106):\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(frontier_risks, frontier_returns, c=np.array(frontier_returns)/np.array(frontier_risks), cmap='YlGnBu', marker='o')\n",
    "    plt.title('Efficient Frontier')\n",
    "    plt.xlabel('Risk (Standard Deviation)')\n",
    "    plt.ylabel('Return')\n",
    "    plt.colorbar(label='Sharpe Ratio')\n",
    "    '''\n",
    "    max_sharpe_idx = np.argmax(np.array(frontier_returns) / np.array(frontier_risks))\n",
    "    max_sharpe_ratio = frontier_returns[max_sharpe_idx] / frontier_risks[max_sharpe_idx]\n",
    "    max_sharpe_return = frontier_returns[max_sharpe_idx]\n",
    "    max_sharpe_risk = frontier_risks[max_sharpe_idx]\n",
    "\n",
    "    #plt.scatter(max_sharpe_risk, max_sharpe_return, marker='*', color='r', s=100, label='Max Sharpe Ratio')\n",
    "\n",
    "    cml_x = [0, max_sharpe_risk]\n",
    "    cml_y = [risk_free_rate, max_sharpe_return]\n",
    "    '''\n",
    "    plt.plot(cml_x, cml_y, color='r', linestyle='--', label='Capital Market Line (CML)')\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    '''\n",
    "\n",
    "    #print(\"Optimal Weights for Maximum Sharpe Ratio Portfolio:\")\n",
    "    weights = []\n",
    "    for i in range(len(frontier_weights[max_sharpe_idx])):\n",
    "        #print(f\"Stock {i+1}: {frontier_weights[max_sharpe_idx][i]:.4f}\")\n",
    "        formatted_value = round(frontier_weights[max_sharpe_idx][i], 4)\n",
    "        weights.append(formatted_value)\n",
    "    return weights\n",
    "\n",
    "def blackLitterman(p_value, q_value):\n",
    "    stock_symbols, time_horizon = get_user_input()\n",
    "\n",
    "    returns = fetch_historical_data(stock_symbols)\n",
    "    expected_returns, cov_matrix = calculate_expected_returns_and_cov_matrix(returns, time_horizon)\n",
    "\n",
    "    # Fetch market capitalizations\n",
    "    market_caps = []\n",
    "    for symbol in stock_symbols:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        market_cap = ticker.info['marketCap']\n",
    "        market_caps.append(market_cap)\n",
    "\n",
    "    equilibrium_returns = calculate_market_equilibrium_returns(cov_matrix, market_caps)\n",
    "\n",
    "    # Define P based on p_value\n",
    "    if p_value == 0:\n",
    "        P = np.array([[1, -1]])\n",
    "    elif p_value == 1:\n",
    "        P = np.array([[-1, 1]])\n",
    "    elif p_value == 2:\n",
    "        P = np.array([[1, 0]])\n",
    "    elif p_value == 3:\n",
    "        P = np.array([[0, 1]])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid p_value. Must be 0, 1, 2, or 3.\")\n",
    "\n",
    "    Q = np.array([q_value])\n",
    "\n",
    "    # Set uncertainty in views (omega) as a diagonal matrix with small values\n",
    "    omega = np.diag([0.0001])\n",
    "\n",
    "    adjusted_returns = adjust_returns_with_views(equilibrium_returns, cov_matrix, P, Q, omega)\n",
    "\n",
    "    #print(\"Expected Returns:\", adjusted_returns)\n",
    "    #print(\"Covariance Matrix:\\n\", cov_matrix)\n",
    "\n",
    "    frontier_returns, frontier_risks, frontier_weights = calculate_efficient_frontier(adjusted_returns, cov_matrix)\n",
    "\n",
    "    return plot_efficient_frontier(frontier_returns, frontier_risks, frontier_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52285a8-2d68-475f-bffc-d9d388930eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "\n",
    "\n",
    "jobdescription = \"You are a portfolio manager and are looking at the changes to a portfolio made from anlysing the sentiment of current news aricles.\"\n",
    "message_1 =\"Hello there! Why have I lost money?\"\n",
    "\n",
    "import sys\n",
    "# Append the directory to your python path using sys\n",
    "sys.path.append('/content/drive/MyDrive')\n",
    "# Import the module\n",
    "\n",
    "from black_litterman import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import csv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "\n",
    "API_KEY = \"02631291-6a1d-4f18-847d-ad4d8dcce934\"\n",
    "# Hyperparameters\n",
    "EMBEDDING_DIM = 768  # BERT embedding dimension\n",
    "HIDDEN_DIM = 256\n",
    "ACTION_SPACE = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "GAMMA = 0.99  # Discount factor for rewards\n",
    "BATCH_SIZE = 10  # Number of episodes before updating the policy\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformer-based Policy Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class TransformerPolicy(nn.Module):\n",
    "    def __init__(self, action_space, hidden_dim=1024, num_layers=24, num_heads=16, use_residual=True, dropout_rate=0.1):\n",
    "        super(TransformerPolicy, self).__init__()\n",
    "        # Load pre-trained BERT model\n",
    "        model_dir = os.path.expanduser(\"~/.cache/huggingface/hub/models--bert-base-uncased\")\n",
    "        if os.path.exists(model_dir):\n",
    "            self.bert = BertModel.from_pretrained('bert-base-uncased', local_files_only=True)\n",
    "        else:\n",
    "            self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased', local_files_only=True)\n",
    "\n",
    "        # Define a much deeper and more complex network\n",
    "        self.use_residual = use_residual\n",
    "        self.layers = nn.ModuleList()\n",
    "        input_dim = self.bert.config.hidden_size  # BERT's hidden size (768 for bert-base-uncased)\n",
    "\n",
    "        # Initial projection to hidden_dim\n",
    "        self.projection = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Multi-head self-attention blocks\n",
    "        self.attention_blocks = nn.ModuleList()\n",
    "        for _ in range(num_layers // 2):  # Add attention blocks every 2 layers\n",
    "            self.attention_blocks.append(\n",
    "                nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "            )\n",
    "\n",
    "        # Deep feed-forward network\n",
    "        for i in range(num_layers):\n",
    "            # Add a linear layer with intermediate expansion\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim * 4),  # Expand dimension\n",
    "                nn.GELU(),\n",
    "                nn.Linear(hidden_dim * 4, hidden_dim),  # Project back to hidden_dim\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ))\n",
    "            # Add Layer Normalization (pre-norm)\n",
    "            self.layers.append(nn.LayerNorm(hidden_dim))\n",
    "\n",
    "        # Final layer to map to action space\n",
    "        self.final_layer = nn.Linear(hidden_dim, action_space)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # Use the [CLS] token representation\n",
    "\n",
    "        # Project BERT output to hidden_dim\n",
    "        x = self.projection(pooled_output)\n",
    "\n",
    "        # Pass through the deep network with attention blocks\n",
    "        attention_block_idx = 0\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, nn.Sequential):  # Feed-forward block\n",
    "                residual = x if self.use_residual else 0\n",
    "                x = layer(x)\n",
    "                if self.use_residual:\n",
    "                    x = x + residual\n",
    "            elif isinstance(layer, nn.LayerNorm):  # Layer normalization\n",
    "                x = layer(x)\n",
    "\n",
    "            # Insert multi-head self-attention every 2 layers\n",
    "            if i % 2 == 0 and attention_block_idx < len(self.attention_blocks):\n",
    "                x = x.unsqueeze(0)  # Add batch dimension for attention\n",
    "                x, _ = self.attention_blocks[attention_block_idx](x, x, x)\n",
    "                x = x.squeeze(0)  # Remove batch dimension\n",
    "                attention_block_idx += 1\n",
    "\n",
    "        # Final layer to produce logits\n",
    "        logits = self.final_layer(x)\n",
    "        logits = torch.clamp(logits, min=-10, max=10)  # Clip logits to avoid extreme values\n",
    "        action_probs = self.softmax(logits + 1e-9)  # Add epsilon for numerical stability\n",
    "        return action_probs\n",
    "\n",
    "\n",
    "# Reinforcement Learning Agent\n",
    "class RLAgent:\n",
    "    def __init__(self, policy_net, optimizer, gamma):\n",
    "        self.policy_net = policy_net\n",
    "        self.optimizer = optimizer\n",
    "        self.gamma = gamma\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        input_ids = state['input_ids'].to(device)\n",
    "        attention_mask = state['attention_mask'].to(device)\n",
    "\n",
    "        # Get action probabilities\n",
    "        action_probs = self.policy_net(input_ids, attention_mask)\n",
    "\n",
    "        # Clone before modification to avoid in-place changes\n",
    "        modified_probs = action_probs.clone()\n",
    "\n",
    "        # Define the excluded action\n",
    "        excluded_action = 0\n",
    "\n",
    "        # Store the probability of the excluded action\n",
    "        excluded_action_prob = modified_probs[0, excluded_action].item()\n",
    "\n",
    "        # Set the probability of the excluded action to 0\n",
    "        modified_probs[0, excluded_action] = 0.0\n",
    "\n",
    "        # Normalize the remaining probabilities\n",
    "        modified_probs = modified_probs / modified_probs.sum()\n",
    "\n",
    "        # Sample an action from the modified probability distribution\n",
    "        m = Categorical(modified_probs)\n",
    "        action = m.sample()\n",
    "\n",
    "        # Save log probability for training\n",
    "        self.saved_log_probs.append(m.log_prob(action))\n",
    "\n",
    "        return action.item(), excluded_action_prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def update_policy(self):\n",
    "        R = 0\n",
    "        policy_loss = []\n",
    "        returns = []\n",
    "\n",
    "        # Calculate discounted returns\n",
    "        for r in self.rewards[::-1]:\n",
    "            R = r + self.gamma * R\n",
    "            returns.insert(0, R)\n",
    "\n",
    "        returns = torch.tensor(returns).to(device)\n",
    "        if len(returns) > 1:  # Only normalize if there are multiple returns\n",
    "            returns = (returns - returns.mean()) / (returns.std() + 1e-9)  # Normalize returns\n",
    "\n",
    "        # Calculate policy loss\n",
    "        for log_prob, R in zip(self.saved_log_probs, returns):\n",
    "            policy_loss.append(-log_prob * R)\n",
    "\n",
    "        # Optimize the policy\n",
    "        self.optimizer.zero_grad()\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "        policy_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Clear saved rewards and log probabilities\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "# Tokenizer for text input\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "@st.cache_resource\n",
    "def load_transformer_policy():\n",
    "    return TransformerPolicy(ACTION_SPACE).to(device)\n",
    "\n",
    "\n",
    "# Initialize policy network and optimizer\n",
    "policy_net = load_transformer_policy()\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "agent = RLAgent(policy_net, optimizer, GAMMA)\n",
    "\n",
    "def load_data():\n",
    "  df1 = pd.read_csv('AppleNewsStock.csv')\n",
    "  df2 = pd.read_csv('MicrosoftNewsStock.csv')\n",
    "  return df1, df2\n",
    "\n",
    "def process_data(df1, df2):\n",
    "  processed_data = []\n",
    "  days = 7\n",
    "  data_chunk = \"\"\n",
    "  for (index1, row1), (index2, row2) in zip(df1.iterrows(), df2.iterrows()):\n",
    "    if days>0:\n",
    "      data_chunk += str(row1['Open'])+str(row1['High'])+str(row1['Low'])+str(row1['Close'])+str(row1['Adj Close'])+str(row1['Volume'])+str(row1['News'])\n",
    "      data_chunk += str(row2['Open'])+str(row2['High'])+str(row2['Low'])+str(row2['Close'])+str(row2['Adj Close'])+str(row2['Volume'])+str(row2['News'])\n",
    "      days-=1\n",
    "    else:\n",
    "      days = 7\n",
    "      processed_data.append(data_chunk)\n",
    "      data_chunk = \"\"\n",
    "  return processed_data\n",
    "\n",
    "def get_news_for_time_period(timestamp):\n",
    "    \"\"\"Retrieve news articles corresponding to a given time period.\"\"\"\n",
    "    df1,df2 = load_data()\n",
    "    filtered_df = df1[df1['Date'] == timestamp]\n",
    "    if not filtered_df.empty:\n",
    "        return filtered_df.iloc[0]['News']\n",
    "    return None\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "class AI(ChatOpenAI):\n",
    "    def __init__(self, model_name=\"Llama-3.3-70B-Instruct\",\n",
    "                 openai_api_key=\"02631291-6a1d-4f18-847d-ad4d8dcce934\",\n",
    "                 openai_api_base=\"https://api.arliai.com/v1\",\n",
    "                 temperature=0.8):\n",
    "\n",
    "        # Call the parent constructor with valid arguments\n",
    "        super().__init__(model_name=model_name, openai_api_key=openai_api_key,openai_api_base=\"https://api.arliai.com/v1\", temperature=temperature)\n",
    "def generate_chatgpt_explanation(p, q, timestamp):\n",
    "    news_articles = get_news_for_time_period(timestamp)\n",
    "    if p == 0:\n",
    "        P = np.array([[1, -1]])\n",
    "    elif p == 1:\n",
    "        P = np.array([[-1, 1]])\n",
    "    elif p == 2:\n",
    "        P = np.array([[1, 0]])\n",
    "    elif p == 3:\n",
    "        P = np.array([[0, 1]])\n",
    "\n",
    "    \"\"\"Generate an explanation for why P and Q values were chosen based on news context.\"\"\"\n",
    "    prompt = f\"\"\" The 0th index in the p value is the apple's stock and the 1st index being microsoft stock.\n",
    "    p values can be of 4 types, [1,-1] which means the price of 0th index is going to outperform the price of 1st index by the amount given in the Q value, [-1,1] means 1st index is going to outperform 2nd index by it's q value,[1,0] means price of 0th index is going to rise by its q value and [0,1] price of 1st index is going to rise by its q value\n",
    "    The following are the P and Q values predicted by a reinforcement learning model:\n",
    "    - P value: {p}\n",
    "    - Q value: {q}\n",
    "\n",
    "    The corresponding news articles for this time period are:\n",
    "    {news_articles}\n",
    "\n",
    "    Based on the news context, explain why these P and Q values were chosen by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    #return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    llm = AI()\n",
    "\n",
    "    messages = [\n",
    "    SystemMessage(content=\"You are a experienced stock portfolio manager.\"),\n",
    "    HumanMessage(content= prompt)]\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "\n",
    "    return(response.content)\n",
    "\n",
    "\n",
    "# Example training loop\n",
    "def train(episodes):\n",
    "    df1, df2 = load_data()\n",
    "    processed_data = process_data(df1, df2)\n",
    "    #return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def main():\n",
    "    x = []\n",
    "    y = []\n",
    "    st.title(\"AI Based Black Litterman Portfolio Optimisation\")\n",
    "    image_url = \"https://easydrawingguides.com/wp-content/uploads/2017/02/How-to-draw-a-cartoon-tree-20.png\"\n",
    "    image_placeholder = st.empty()\n",
    "\n",
    "    # Load and process data\n",
    "    df1, df2 = load_data()\n",
    "    processed_data = process_data(df1, df2)\n",
    "    \n",
    "    # Initialize policy network and RL agent\n",
    "    policy_net = load_transformer_policy()\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "    agent = RLAgent(policy_net, optimizer, GAMMA)\n",
    "\n",
    "    episodes = 300-240\n",
    "    balance=10000\n",
    "\n",
    "    for episode in range(episodes):\n",
    "      if episode%7==0:\n",
    "        text = processed_data[episode]\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        # Select action\n",
    "        action, excluded_action_prob = agent.select_action(inputs)\n",
    "        explanation = generate_chatgpt_explanation(p = action, q = excluded_action_prob,timestamp = df1.iloc[episode].loc['Date'])\n",
    "        st.write(f\"Episode {episode + 1}: Selected Action: {action}, Q-value: {excluded_action_prob}\")\n",
    "        aapl, msft= blackLitterman(action-1, excluded_action_prob)\n",
    "\n",
    "\n",
    "        st.write(f\"The weights for the first week's optimised portfolio: Apple: {aapl}, Microsoft: {msft}\")\n",
    "\n",
    "        aapl_in_pounds = balance*aapl\n",
    "        msft_in_pounds = balance*msft\n",
    "\n",
    "        st.write(f\"Apple: {df1.iloc[episode].loc['Date']}\")\n",
    "        st.write(f\"Microsoft: {df2.iloc[episode].loc['Date']}\")\n",
    "\n",
    "        aapl_shares = aapl_in_pounds/df1.iloc[episode].loc['Open']\n",
    "        msft_shares = msft_in_pounds/df2.iloc[episode].loc['Open']\n",
    "\n",
    "\n",
    "\n",
    "        aapl_sell_price = aapl_shares * (df1.iloc[episode+3].loc['Open'])\n",
    "        msft_sell_price = msft_shares * (df2.iloc[episode+3].loc['Open'])\n",
    "\n",
    "        if \"show_image\" not in st.session_state:\n",
    "          st.session_state[\"show_image\"] = True\n",
    "\n",
    "        if st.session_state[\"show_image\"]:\n",
    "          image_placeholder.image(image_url, use_column_width=True)\n",
    "        else:\n",
    "          image_placeholder.empty()\n",
    "\n",
    "        aapl_profit = aapl_sell_price-aapl_in_pounds\n",
    "        msft_profit = msft_sell_price-msft_in_pounds\n",
    "        total_profit = msft_profit+aapl_profit\n",
    "        if total_profit<0:\n",
    "          total_profit*=-1\n",
    "        st.write(f\"Total Profit: {total_profit}\")\n",
    "    # Streamlit Sidebar UI\n",
    "    with st.sidebar:\n",
    "        st.write(\"AI-based Stock Portfolio Optimization\")\n",
    "\n",
    "        # Sample explanation generation\n",
    "        timestamp = df1.iloc[0]['Date']  # Example: Taking the first date from dataset\n",
    "        p, q = 2, 0.05  # Example P and Q values\n",
    "        st.write(\"AI Explanation for P and Q Values:\")\n",
    "        st.write(explanation)\n",
    "\n",
    "\n",
    "    st.write(\"Portfolio Optimization Completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10af7e5-bec3-4fa8-a4c4-4af398cf6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb921503-d32b-4015-a18d-01fca7b6bf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff83119-2969-4bae-ad5a-6f2bcb513468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
